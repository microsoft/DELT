New Epoch
[1, 315, 506, 624, 7087, 28725, 438, 2429, 378, 349, 7087, 298, 528, 28725, 298, 2264, 8217, 272, 1432, 4009, 302, 272, 3085, 7499, 28723, 2326, 272, 3454, 7499, 315, 403, 2358, 298, 1149, 707, 1707, 395, 264, 9522, 16741, 28725, 562, 395, 456, 2751, 1080, 302, 272, 727, 739, 315, 1149, 395, 264, 9522, 16741, 28725, 272, 2039, 1235, 459, 11286, 272, 1707, 315, 837, 18289, 298, 13050, 28723, 7336, 456, 8284, 1479, 28804, 1047, 459, 28725, 349, 378, 1368, 3909, 298, 2962, 1159, 272, 1679, 4009, 349, 11793, 28804, 13, 22893, 354, 272, 4517, 28723, 315, 776, 3851, 378, 356, 586, 8955, 16430, 20000, 304, 272, 9522, 16741, 349, 2739, 28705, 28740, 28734, 28734, 28823, 354, 528, 28723, 7336, 272, 1707, 302, 264, 2552, 3575, 28804, 315, 3851, 582, 298, 264, 3522, 5498, 1707, 28723, 13, 28741, 633, 4480, 302, 10918, 10022, 369, 315, 682, 3555, 349, 272, 5537, 298, 6580, 380, 272, 5498, 2293, 5573, 28733, 10487, 3578, 3519, 302, 1743, 9917, 3578, 28723, 6005, 1865, 338, 1238, 6792, 18134, 477, 989, 6735, 14666, 5651, 438, 272, 1348, 2962, 28723, 2387, 553, 12564, 3082, 19617, 28723, 415, 799, 1539, 28809, 28707, 28723, 7267, 6384, 374, 28725, 1162, 28733, 501, 2148, 286, 25308, 460, 19225, 354, 652, 1166, 1711, 1467, 28745, 315, 506, 708, 3028, 2079, 264, 981, 1209, 9373, 320, 849, 2117, 451, 1127, 18061, 28838, 6948, 16252, 352, 27156, 1209, 9373, 261, 849, 2117, 3435, 395, 289, 1127, 18061, 28838, 557, 1312, 799, 28725, 680, 25285, 28725, 4907, 28725, 1259, 390, 981, 28735, 14245, 28838, 511, 459, 28723, 13, 28755, 903, 302, 272, 480, 350, 4689, 18756, 3479, 304, 23660, 3706, 526, 361, 2285, 315, 24014, 28723, 851, 3157, 28809, 28707, 272, 771, 302, 264, 8271, 4300, 17153, 693, 8108, 582, 9638, 298, 16287, 11466, 297, 516, 442, 559, 8271, 13821, 28725, 562, 369, 302, 2493, 354, 6105, 4300, 349, 264, 1676, 3842, 28723, 415, 754, 1730, 302, 981, 2913, 588, 21834, 28838, 315, 13128, 356, 1176, 28709, 12017, 2235, 778, 272, 754, 10381, 1526, 302, 2887, 616, 664, 1771, 297, 18569, 302, 4695, 5436, 28723, 13, 12973, 1065, 460, 264, 1581, 446, 2973, 291, 302, 8006, 28725, 579, 298, 4085, 28725, 1019, 739, 652, 8926, 668, 3572, 349, 5444, 28723, 7110, 478, 506, 5223, 5166, 9235, 297, 272, 1432, 1370, 4434, 684, 427, 375, 1349, 274, 28723, 13, 1014, 427, 375, 1349, 349, 981, 303, 27559, 395, 11334, 6804, 6138, 559, 1816, 28725, 304, 14259, 2710, 3000, 298, 4737, 19894, 733, 28713, 294, 28793, 272, 11334, 28712, 617, 302, 272, 559, 1816, 7445, 315, 10361, 369, 2825, 590, 949, 28809, 28707, 2608, 1388, 22446, 1843, 28733, 663, 28726, 18796, 28725, 736, 1250, 708, 2764, 354, 706, 28723, 9447, 7373, 302, 427, 375, 1349, 274, 15291, 3892, 754, 3534, 6163, 2208, 4230, 294, 363, 788, 354, 668, 28708, 28733, 4091, 19070, 466, 28723, 9447, 590, 576, 298, 272, 16699, 438, 272, 948, 302, 272, 1370, 354, 264, 21337, 28733, 715, 28723, 13, 657, 707, 1951, 28725, 427, 375, 1349, 274, 2622, 737, 590, 28809, 28715, 347, 1368, 2475, 354, 586, 9703, 28725, 1019, 513, 590, 511, 865, 2434, 7642, 28740, 28750, 28723, 28774, 28782, 28723, 2326, 420, 10112, 2480, 2178, 11540, 486, 1295, 5810, 16722, 28725, 5671, 28723, 356, 574, 25773, 265, 10230, 15472, 1611, 442, 3667, 28725, 574, 16492, 1532, 622, 347, 6129, 12364, 28808, 1295, 5810, 16722, 28725, 5671, 28723, 659, 750, 4430, 288, 1830, 4045, 319, 10112, 16113, 297, 25773, 265, 10230, 1854, 28705, 28750, 28734, 28734, 28774, 28723, 1684, 378, 3435, 298, 25773, 265, 10230, 319, 10112, 16113, 28725, 1295, 5810, 16722, 28725, 5671, 28723, 5751, 2936, 304, 16662, 14843, 28723, 20066, 5023, 356, 272, 3414, 1312, 1295, 5810, 16722, 28725, 5671, 1815, 28713, 319, 10112, 16113, 1840, 8049, 304, 2323, 11878, 575, 302, 574, 25773, 265, 10230, 16492, 1532, 28723, 13, 1014, 16492, 1532, 356, 574, 25773, 265, 10230, 1611, 442, 3667, 506, 624, 6032, 28747, 16652, 346, 890, 2035, 7296, 2130, 1753, 477, 574, 9145, 304, 1753, 477, 574, 13865, 28723, 2326, 1295, 5810, 16722, 28725, 5671, 28723, 11540, 25773, 265, 10230, 420, 10112, 2480, 2178, 574, 319, 10112, 622, 6344, 1933, 302, 533, 476, 3080, 27531, 28723, 1682, 15675,
I have one negative, at least it is negative to me, to report regarding the last update of the words database. With the previous database I was able to start any word with a blank tile, but with this version most of the time when I start with a blank tile, the game does not recognize the word I am attempting to spell. Was this intentional? If not, is it too late to address before the next update is issued?
Thanks for the comment. I just tried it on my Windows Mobile Device and the blank tile is working 100% for me. Was the word of a certain length? I tried up to a six letter word.
A new feature of WordPop that I would enjoy is the ability to rotate the letter array counter-clockwise instead of always clockwise. Two brochures arrived simultaneously from two Indian restaurants located at the same address. One had decent copy editing. The other didn’t. Its earnest, well-intentioned descriptions are notable for their erraticness; I have no idea why a “Chicken Tikka Omelette” requires elaboration (“Chicken tikka comes with omelette”), while other, more vague, items, such as “Soup” do not.
Much of the shoddy grammar and phrasing quirks I forgive. This isn’t the work of a native English speaker who grew up unable to communicate effectively in his or her native tongue, but that of someone for whom English is a second language. The overuse of “succulent” I blame on indoctrination into the overdone world of food adjectives in lieu of actual description.
Typos are a different kettle of fish, so to speak, even when their intended spelling is obvious. Thus we have spent multiple moments in the last day talking about seabusses.
The seabuss is “stuffed with fragrant fresh herbs, and gently steamed toabsorb [sic] the fragrance of the herbs”. I suppose that means they don’t often take aboard non-herb passengers, there being no space for them. Perhaps schools of seabusses steam themselves over deep sea volcanic vents for spa-like refreshment. Perhaps they go to the garage at the end of the day for a tune-up.
In any event, seabusses sound like they’d be too large for my plate, even if they do only cost £12.95. With Gutter Guards installed by Shingle Express, Inc. on your Southeastern Pennsylvania home or building, your gutters will be zero maintenance! Shingle Express, Inc. has been installing top quality gutter guards in Southeastern since 2009. When it comes to Southeastern gutter guards, Shingle Express, Inc. offers quick and affordable installation. Stay safe on the ground while Shingle Express, Inc.'s gutter guards keep leaves and twigs out of your Southeastern gutters.
The gutters on your Southeastern home or building have one purpose: Quickly divert rain water away from your roof and away from your foundation. With Shingle Express, Inc. installed Southeastern Gutter Guards your gutter will remain free of clogging debris. Allowing your Southeastern building to last longer with less maintenance. Shingle Express, Inc. installed Gutter Guards in Southeastern are a wise investment, as they provide years, even decades of protection to your Southeastern gutters and home.
Its dangerous work climbing ladders to clean your Southeastern gutters. With Shingle Express, Inc. installed Gutter Guards, your Southeastern home or building gutters will basically be maintenance free. No more pulling wet muck while perched on a shaky ladder. No more paying a handyman to clean your Southeastern gutters. You'll retain your time, your money and your health with Gutter Guards on your Southeastern home.
Another storms is coming. Will your Southeastern gutters be guarded? Why wait? Call Shingle Express, Inc. now for a fast, friendly and free quote on Southeastern gutter guards. Protect your Southeastern gutters, home, investment, and health. Call Shingle Express, Inc. to install gutter guards on your Southeastern property today! The following article was published in the Hartford Business Journal, you can view the original article here.
When the Tax and Jobs Act of 2017 was signed into law by President Trump last year, it was the most significant change to tax policy our country has seen in more than 30 years
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
[315, 506, 624, 7087, 28725, 438, 2429, 378, 349, 7087, 298, 528, 28725, 298, 2264, 8217, 272, 1432, 4009, 302, 272, 3085, 7499, 28723, 2326, 272, 3454, 7499, 315, 403, 2358, 298, 1149, 707, 1707, 395, 264, 9522, 16741, 28725, 562, 395, 456, 2751, 1080, 302, 272, 727, 739, 315, 1149, 395, 264, 9522, 16741, 28725, 272, 2039, 1235, 459, 11286, 272, 1707, 315, 837, 18289, 298, 13050, 28723, 7336, 456, 8284, 1479, 28804, 1047, 459, 28725, 349, 378, 1368, 3909, 298, 2962, 1159, 272, 1679, 4009, 349, 11793, 28804, 13, 22893, 354, 272, 4517, 28723, 315, 776, 3851, 378, 356, 586, 8955, 16430, 20000, 304, 272, 9522, 16741, 349, 2739, 28705, 28740, 28734, 28734, 28823, 354, 528, 28723, 7336, 272, 1707, 302, 264, 2552, 3575, 28804, 315, 3851, 582, 298, 264, 3522, 5498, 1707, 28723, 13, 28741, 633, 4480, 302, 10918, 10022, 369, 315, 682, 3555, 349, 272, 5537, 298, 6580, 380, 272, 5498, 2293, 5573, 28733, 10487, 3578, 3519, 302, 1743, 9917, 3578, 28723, 6005, 1865, 338, 1238, 6792, 18134, 477, 989, 6735, 14666, 5651, 438, 272, 1348, 2962, 28723, 2387, 553, 12564, 3082, 19617, 28723, 415, 799, 1539, 28809, 28707, 28723, 7267, 6384, 374, 28725, 1162, 28733, 501, 2148, 286, 25308, 460, 19225, 354, 652, 1166, 1711, 1467, 28745, 315, 506, 708, 3028, 2079, 264, 981, 1209, 9373, 320, 849, 2117, 451, 1127, 18061, 28838, 6948, 16252, 352, 27156, 1209, 9373, 261, 849, 2117, 3435, 395, 289, 1127, 18061, 28838, 557, 1312, 799, 28725, 680, 25285, 28725, 4907, 28725, 1259, 390, 981, 28735, 14245, 28838, 511, 459, 28723, 13, 28755, 903, 302, 272, 480, 350, 4689, 18756, 3479, 304, 23660, 3706, 526, 361, 2285, 315, 24014, 28723, 851, 3157, 28809, 28707, 272, 771, 302, 264, 8271, 4300, 17153, 693, 8108, 582, 9638, 298, 16287, 11466, 297, 516, 442, 559, 8271, 13821, 28725, 562, 369, 302, 2493, 354, 6105, 4300, 349, 264, 1676, 3842, 28723, 415, 754, 1730, 302, 981, 2913, 588, 21834, 28838, 315, 13128, 356, 1176, 28709, 12017, 2235, 778, 272, 754, 10381, 1526, 302, 2887, 616, 664, 1771, 297, 18569, 302, 4695, 5436, 28723, 13, 12973, 1065, 460, 264, 1581, 446, 2973, 291, 302, 8006, 28725, 579, 298, 4085, 28725, 1019, 739, 652, 8926, 668, 3572, 349, 5444, 28723, 7110, 478, 506, 5223, 5166, 9235, 297, 272, 1432, 1370, 4434, 684, 427, 375, 1349, 274, 28723, 13, 1014, 427, 375, 1349, 349, 981, 303, 27559, 395, 11334, 6804, 6138, 559, 1816, 28725, 304, 14259, 2710, 3000, 298, 4737, 19894, 733, 28713, 294, 28793, 272, 11334, 28712, 617, 302, 272, 559, 1816, 7445, 315, 10361, 369, 2825, 590, 949, 28809, 28707, 2608, 1388, 22446, 1843, 28733, 663, 28726, 18796, 28725, 736, 1250, 708, 2764, 354, 706, 28723, 9447, 7373, 302, 427, 375, 1349, 274, 15291, 3892, 754, 3534, 6163, 2208, 4230, 294, 363, 788, 354, 668, 28708, 28733, 4091, 19070, 466, 28723, 9447, 590, 576, 298, 272, 16699, 438, 272, 948, 302, 272, 1370, 354, 264, 21337, 28733, 715, 28723, 13, 657, 707, 1951, 28725, 427, 375, 1349, 274, 2622, 737, 590, 28809, 28715, 347, 1368, 2475, 354, 586, 9703, 28725, 1019, 513, 590, 511, 865, 2434, 7642, 28740, 28750, 28723, 28774, 28782, 28723, 2326, 420, 10112, 2480, 2178, 11540, 486, 1295, 5810, 16722, 28725, 5671, 28723, 356, 574, 25773, 265, 10230, 15472, 1611, 442, 3667, 28725, 574, 16492, 1532, 622, 347, 6129, 12364, 28808, 1295, 5810, 16722, 28725, 5671, 28723, 659, 750, 4430, 288, 1830, 4045, 319, 10112, 16113, 297, 25773, 265, 10230, 1854, 28705, 28750, 28734, 28734, 28774, 28723, 1684, 378, 3435, 298, 25773, 265, 10230, 319, 10112, 16113, 28725, 1295, 5810, 16722, 28725, 5671, 28723, 5751, 2936, 304, 16662, 14843, 28723, 20066, 5023, 356, 272, 3414, 1312, 1295, 5810, 16722, 28725, 5671, 1815, 28713, 319, 10112, 16113, 1840, 8049, 304, 2323, 11878, 575, 302, 574, 25773, 265, 10230, 16492, 1532, 28723, 13, 1014, 16492, 1532, 356, 574, 25773, 265, 10230, 1611, 442, 3667, 506, 624, 6032, 28747, 16652, 346, 890, 2035, 7296, 2130, 1753, 477, 574, 9145, 304, 1753, 477, 574, 13865, 28723, 2326, 1295, 5810, 16722, 28725, 5671, 28723, 11540, 25773, 265, 10230, 420, 10112, 2480, 2178, 574, 319, 10112, 622, 6344, 1933, 302, 533, 476, 3080, 27531, 28723, 1682, 15675, 574
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)
{'loss': 10.545635223388672, 'elasped_time': 0.8609533309936523}
train | epoch 0/1 | steps 0 | global_steps 1/6017 | loss: 10.545635 | elasped_time: 0.860953 | lr: 0.0000e+00 | scale: 2048
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
{'loss': 10.519769501686095, 'elasped_time': 0.2274109959602356}
****************************************************************************************************
train | epoch 0/1 | steps 39 | global_steps 10/6017 | loss: 10.519770 | elasped_time: 0.227411 | grad_norm: 3.5527 | lr: 3.0000e-06 | scale: 2048 | step_time: 0.9096 | real_step_time: 1.1206
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
Model save to models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr/10
{'loss': 10.325373983383178, 'elasped_time': 0.20824743509292604}
****************************************************************************************************
train | epoch 0/1 | steps 79 | global_steps 20/6017 | loss: 10.325374 | elasped_time: 0.208247 | grad_norm: 3.4495 | lr: 6.0000e-06 | scale: 2048 | step_time: 0.8330 | real_step_time: 0.9196
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 9.939479756355286, 'elasped_time': 0.20834419131278992}
****************************************************************************************************
train | epoch 0/1 | steps 119 | global_steps 30/6017 | loss: 9.939480 | elasped_time: 0.208344 | grad_norm: 2.6334 | lr: 9.0000e-06 | scale: 2048 | step_time: 0.8334 | real_step_time: 0.8555
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 9.545658040046693, 'elasped_time': 0.2086143136024475}
****************************************************************************************************
train | epoch 0/1 | steps 159 | global_steps 40/6017 | loss: 9.545658 | elasped_time: 0.208614 | grad_norm: 2.0344 | lr: 1.2000e-05 | scale: 2048 | step_time: 0.8345 | real_step_time: 0.8565
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 9.27781708240509, 'elasped_time': 0.20904222130775452}
****************************************************************************************************
train | epoch 0/1 | steps 199 | global_steps 50/6017 | loss: 9.277817 | elasped_time: 0.209042 | grad_norm: 1.8132 | lr: 1.5000e-05 | scale: 2048 | step_time: 0.8362 | real_step_time: 0.8583
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 9.119166231155395, 'elasped_time': 0.209370756149292}
****************************************************************************************************
train | epoch 0/1 | steps 239 | global_steps 60/6017 | loss: 9.119166 | elasped_time: 0.209371 | grad_norm: 1.7474 | lr: 1.8000e-05 | scale: 2048 | step_time: 0.8375 | real_step_time: 0.8595
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 8.955569458007812, 'elasped_time': 0.20974974632263182}
****************************************************************************************************
train | epoch 0/1 | steps 279 | global_steps 70/6017 | loss: 8.955569 | elasped_time: 0.209750 | grad_norm: 1.6667 | lr: 2.1000e-05 | scale: 2048 | step_time: 0.8390 | real_step_time: 0.8609
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 8.793007969856262, 'elasped_time': 0.2097279191017151}
****************************************************************************************************
train | epoch 0/1 | steps 319 | global_steps 80/6017 | loss: 8.793008 | elasped_time: 0.209728 | grad_norm: 1.5682 | lr: 2.4000e-05 | scale: 2048 | step_time: 0.8389 | real_step_time: 0.8607
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 8.565500116348266, 'elasped_time': 0.21018104553222655}
****************************************************************************************************
train | epoch 0/1 | steps 359 | global_steps 90/6017 | loss: 8.565500 | elasped_time: 0.210181 | grad_norm: 1.5552 | lr: 2.7000e-05 | scale: 2048 | step_time: 0.8407 | real_step_time: 0.8630
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 8.373069906234742, 'elasped_time': 0.21029295921325683}
****************************************************************************************************
train | epoch 0/1 | steps 399 | global_steps 100/6017 | loss: 8.373070 | elasped_time: 0.210293 | grad_norm: 1.3644 | lr: 3.0000e-05 | scale: 2048 | step_time: 0.8412 | real_step_time: 0.8633
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
Model save to models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr/100
{'loss': 8.163412690162659, 'elasped_time': 0.21019311547279357}
****************************************************************************************************
train | epoch 0/1 | steps 439 | global_steps 110/6017 | loss: 8.163413 | elasped_time: 0.210193 | grad_norm: 1.2975 | lr: 3.3000e-05 | scale: 2048 | step_time: 0.8408 | real_step_time: 0.9265
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 7.947529232501983, 'elasped_time': 0.21027351617813111}
****************************************************************************************************
train | epoch 0/1 | steps 479 | global_steps 120/6017 | loss: 7.947529 | elasped_time: 0.210274 | grad_norm: 1.2161 | lr: 3.6000e-05 | scale: 2048 | step_time: 0.8411 | real_step_time: 0.8632
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 7.703578317165375, 'elasped_time': 0.2103282928466797}
****************************************************************************************************
train | epoch 0/1 | steps 519 | global_steps 130/6017 | loss: 7.703578 | elasped_time: 0.210328 | grad_norm: 1.1173 | lr: 3.9000e-05 | scale: 2048 | step_time: 0.8413 | real_step_time: 0.8634
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 7.555062270164489, 'elasped_time': 0.21055113673210143}
****************************************************************************************************
train | epoch 0/1 | steps 559 | global_steps 140/6017 | loss: 7.555062 | elasped_time: 0.210551 | grad_norm: 1.0897 | lr: 4.2000e-05 | scale: 2048 | step_time: 0.8422 | real_step_time: 0.8646
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 7.437861704826355, 'elasped_time': 0.21065918803215028}
****************************************************************************************************
train | epoch 0/1 | steps 599 | global_steps 150/6017 | loss: 7.437862 | elasped_time: 0.210659 | grad_norm: 0.8271 | lr: 4.5000e-05 | scale: 2048 | step_time: 0.8426 | real_step_time: 0.8647
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 7.296551704406738, 'elasped_time': 0.21070221662521363}
****************************************************************************************************
train | epoch 0/1 | steps 639 | global_steps 160/6017 | loss: 7.296552 | elasped_time: 0.210702 | grad_norm: 0.6360 | lr: 4.8000e-05 | scale: 2048 | step_time: 0.8428 | real_step_time: 0.8649
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 7.2096067547798155, 'elasped_time': 0.21080037355422973}
****************************************************************************************************
train | epoch 0/1 | steps 679 | global_steps 170/6017 | loss: 7.209607 | elasped_time: 0.210800 | grad_norm: 0.6579 | lr: 5.1000e-05 | scale: 2048 | step_time: 0.8432 | real_step_time: 0.8653
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 7.136759030818939, 'elasped_time': 0.21086416840553285}
****************************************************************************************************
train | epoch 0/1 | steps 719 | global_steps 180/6017 | loss: 7.136759 | elasped_time: 0.210864 | grad_norm: 0.9058 | lr: 5.4000e-05 | scale: 2048 | step_time: 0.8435 | real_step_time: 0.8656
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 7.094650197029114, 'elasped_time': 0.2108767807483673}
****************************************************************************************************
train | epoch 0/1 | steps 759 | global_steps 190/6017 | loss: 7.094650 | elasped_time: 0.210877 | grad_norm: 0.8961 | lr: 5.7000e-05 | scale: 2048 | step_time: 0.8435 | real_step_time: 0.8655
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 7.039321565628052, 'elasped_time': 0.21091473698616028}
****************************************************************************************************
train | epoch 0/1 | steps 799 | global_steps 200/6017 | loss: 7.039322 | elasped_time: 0.210915 | grad_norm: 0.7663 | lr: 6.0000e-05 | scale: 2048 | step_time: 0.8437 | real_step_time: 0.8657
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.923758161067963, 'elasped_time': 0.21097707748413086}
****************************************************************************************************
train | epoch 0/1 | steps 839 | global_steps 210/6017 | loss: 6.923758 | elasped_time: 0.210977 | grad_norm: 1.4998 | lr: 6.3000e-05 | scale: 2048 | step_time: 0.8439 | real_step_time: 0.8660
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.87792843580246, 'elasped_time': 0.21102551817893983}
****************************************************************************************************
train | epoch 0/1 | steps 879 | global_steps 220/6017 | loss: 6.877928 | elasped_time: 0.211026 | grad_norm: 0.8755 | lr: 6.6000e-05 | scale: 2048 | step_time: 0.8441 | real_step_time: 0.8664
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.814471101760864, 'elasped_time': 0.2111321747303009}
****************************************************************************************************
train | epoch 0/1 | steps 919 | global_steps 230/6017 | loss: 6.814471 | elasped_time: 0.211132 | grad_norm: 0.9340 | lr: 6.9000e-05 | scale: 2048 | step_time: 0.8445 | real_step_time: 0.8669
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.751801455020905, 'elasped_time': 0.2112289547920227}
****************************************************************************************************
train | epoch 0/1 | steps 959 | global_steps 240/6017 | loss: 6.751801 | elasped_time: 0.211229 | grad_norm: 0.8277 | lr: 7.2000e-05 | scale: 2048 | step_time: 0.8449 | real_step_time: 0.8672
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.6793858170509335, 'elasped_time': 0.21111595034599304}
****************************************************************************************************
train | epoch 0/1 | steps 999 | global_steps 250/6017 | loss: 6.679386 | elasped_time: 0.211116 | grad_norm: 0.8278 | lr: 7.5000e-05 | scale: 2048 | step_time: 0.8445 | real_step_time: 0.8667
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.641586327552796, 'elasped_time': 0.21120635867118837}
****************************************************************************************************
train | epoch 0/1 | steps 1039 | global_steps 260/6017 | loss: 6.641586 | elasped_time: 0.211206 | grad_norm: 0.9435 | lr: 7.8000e-05 | scale: 2048 | step_time: 0.8448 | real_step_time: 0.8672
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.584962844848633, 'elasped_time': 0.21108928322792053}
****************************************************************************************************
train | epoch 0/1 | steps 1079 | global_steps 270/6017 | loss: 6.584963 | elasped_time: 0.211089 | grad_norm: 0.7111 | lr: 8.1000e-05 | scale: 2048 | step_time: 0.8444 | real_step_time: 0.8666
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.493658339977264, 'elasped_time': 0.21118828654289246}
****************************************************************************************************
train | epoch 0/1 | steps 1119 | global_steps 280/6017 | loss: 6.493658 | elasped_time: 0.211188 | grad_norm: 0.7336 | lr: 8.4000e-05 | scale: 2048 | step_time: 0.8448 | real_step_time: 0.8669
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.475390899181366, 'elasped_time': 0.21117616295814515}
****************************************************************************************************
train | epoch 0/1 | steps 1159 | global_steps 290/6017 | loss: 6.475391 | elasped_time: 0.211176 | grad_norm: 1.0104 | lr: 8.7000e-05 | scale: 2048 | step_time: 0.8447 | real_step_time: 0.8668
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.448387002944946, 'elasped_time': 0.21121837496757506}
****************************************************************************************************
train | epoch 0/1 | steps 1199 | global_steps 300/6017 | loss: 6.448387 | elasped_time: 0.211218 | grad_norm: 0.9371 | lr: 9.0000e-05 | scale: 2048 | step_time: 0.8449 | real_step_time: 0.8671
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.410286438465119, 'elasped_time': 0.21128824949264527}
****************************************************************************************************
train | epoch 0/1 | steps 1239 | global_steps 310/6017 | loss: 6.410286 | elasped_time: 0.211288 | grad_norm: 1.1046 | lr: 9.3000e-05 | scale: 2048 | step_time: 0.8452 | real_step_time: 0.8673
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.33487833738327, 'elasped_time': 0.21128315925598146}
****************************************************************************************************
train | epoch 0/1 | steps 1279 | global_steps 320/6017 | loss: 6.334878 | elasped_time: 0.211283 | grad_norm: 0.9249 | lr: 9.6000e-05 | scale: 2048 | step_time: 0.8451 | real_step_time: 0.8674
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.313428521156311, 'elasped_time': 0.21133390069007874}
****************************************************************************************************
train | epoch 0/1 | steps 1319 | global_steps 330/6017 | loss: 6.313429 | elasped_time: 0.211334 | grad_norm: 1.1409 | lr: 9.9000e-05 | scale: 2048 | step_time: 0.8453 | real_step_time: 0.8679
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.28020544052124, 'elasped_time': 0.21123392581939698}
****************************************************************************************************
train | epoch 0/1 | steps 1359 | global_steps 340/6017 | loss: 6.280205 | elasped_time: 0.211234 | grad_norm: 0.9889 | lr: 1.0200e-04 | scale: 2048 | step_time: 0.8449 | real_step_time: 0.8671
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.2489540576934814, 'elasped_time': 0.21129024624824524}
****************************************************************************************************
train | epoch 0/1 | steps 1399 | global_steps 350/6017 | loss: 6.248954 | elasped_time: 0.211290 | grad_norm: 1.0247 | lr: 1.0500e-04 | scale: 2048 | step_time: 0.8452 | real_step_time: 0.8674
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.1989687323570255, 'elasped_time': 0.21133218407630922}
****************************************************************************************************
train | epoch 0/1 | steps 1439 | global_steps 360/6017 | loss: 6.198969 | elasped_time: 0.211332 | grad_norm: 0.8020 | lr: 1.0800e-04 | scale: 2048 | step_time: 0.8453 | real_step_time: 0.8673
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.1300772547721865, 'elasped_time': 0.21131858825683594}
****************************************************************************************************
train | epoch 0/1 | steps 1479 | global_steps 370/6017 | loss: 6.130077 | elasped_time: 0.211319 | grad_norm: 1.0205 | lr: 1.1100e-04 | scale: 2048 | step_time: 0.8453 | real_step_time: 0.8672
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.182336938381195, 'elasped_time': 0.21120916604995726}
****************************************************************************************************
train | epoch 0/1 | steps 1519 | global_steps 380/6017 | loss: 6.182337 | elasped_time: 0.211209 | grad_norm: 0.9947 | lr: 1.1400e-04 | scale: 2048 | step_time: 0.8448 | real_step_time: 0.8668
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.077042889595032, 'elasped_time': 0.2112978994846344}
****************************************************************************************************
train | epoch 0/1 | steps 1559 | global_steps 390/6017 | loss: 6.077043 | elasped_time: 0.211298 | grad_norm: 0.9260 | lr: 1.1700e-04 | scale: 2048 | step_time: 0.8452 | real_step_time: 0.8674
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.0479490756988525, 'elasped_time': 0.21124622821807862}
****************************************************************************************************
train | epoch 0/1 | steps 1599 | global_steps 400/6017 | loss: 6.047949 | elasped_time: 0.211246 | grad_norm: 0.9107 | lr: 1.2000e-04 | scale: 2048 | step_time: 0.8450 | real_step_time: 0.8670
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.034270763397217, 'elasped_time': 0.21117877960205078}
****************************************************************************************************
train | epoch 0/1 | steps 1639 | global_steps 410/6017 | loss: 6.034271 | elasped_time: 0.211179 | grad_norm: 1.0426 | lr: 1.2300e-04 | scale: 2048 | step_time: 0.8447 | real_step_time: 0.8668
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 6.033424508571625, 'elasped_time': 0.2112693667411804}
****************************************************************************************************
train | epoch 0/1 | steps 1679 | global_steps 420/6017 | loss: 6.033425 | elasped_time: 0.211269 | grad_norm: 0.9053 | lr: 1.2600e-04 | scale: 2048 | step_time: 0.8451 | real_step_time: 0.8671
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 5.924981391429901, 'elasped_time': 0.21117315888404847}
****************************************************************************************************
train | epoch 0/1 | steps 1719 | global_steps 430/6017 | loss: 5.924981 | elasped_time: 0.211173 | grad_norm: 0.9882 | lr: 1.2900e-04 | scale: 2048 | step_time: 0.8447 | real_step_time: 0.8664
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 5.946021270751953, 'elasped_time': 0.2112309992313385}
****************************************************************************************************
train | epoch 0/1 | steps 1759 | global_steps 440/6017 | loss: 5.946021 | elasped_time: 0.211231 | grad_norm: 0.8254 | lr: 1.3200e-04 | scale: 2048 | step_time: 0.8449 | real_step_time: 0.8672
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 5.905503678321838, 'elasped_time': 0.2112454354763031}
****************************************************************************************************
train | epoch 0/1 | steps 1799 | global_steps 450/6017 | loss: 5.905504 | elasped_time: 0.211245 | grad_norm: 1.0571 | lr: 1.3500e-04 | scale: 2048 | step_time: 0.8450 | real_step_time: 0.8674
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 5.886887848377228, 'elasped_time': 0.21124747395515442}
****************************************************************************************************
train | epoch 0/1 | steps 1839 | global_steps 460/6017 | loss: 5.886888 | elasped_time: 0.211247 | grad_norm: 0.9670 | lr: 1.3800e-04 | scale: 2048 | step_time: 0.8450 | real_step_time: 0.8672
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 5.854633295536042, 'elasped_time': 0.21124411821365358}
****************************************************************************************************
train | epoch 0/1 | steps 1879 | global_steps 470/6017 | loss: 5.854633 | elasped_time: 0.211244 | grad_norm: 0.9749 | lr: 1.4100e-04 | scale: 2048 | step_time: 0.8450 | real_step_time: 0.8670
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 5.823152124881744, 'elasped_time': 0.21118921041488647}
****************************************************************************************************
train | epoch 0/1 | steps 1919 | global_steps 480/6017 | loss: 5.823152 | elasped_time: 0.211189 | grad_norm: 0.8358 | lr: 1.4400e-04 | scale: 2048 | step_time: 0.8448 | real_step_time: 0.8665
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 5.724252104759216, 'elasped_time': 0.21115964651107788}
****************************************************************************************************
train | epoch 0/1 | steps 1959 | global_steps 490/6017 | loss: 5.724252 | elasped_time: 0.211160 | grad_norm: 1.0238 | lr: 1.4700e-04 | scale: 2048 | step_time: 0.8446 | real_step_time: 0.8664
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 5.72555388212204, 'elasped_time': 0.21128055453300476}
****************************************************************************************************
train | epoch 0/1 | steps 1999 | global_steps 500/6017 | loss: 5.725554 | elasped_time: 0.211281 | grad_norm: 1.0992 | lr: 1.5000e-04 | scale: 2048 | step_time: 0.8451 | real_step_time: 0.8666
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 5.750401723384857, 'elasped_time': 0.211144882440567}
****************************************************************************************************
train | epoch 0/1 | steps 2039 | global_steps 510/6017 | loss: 5.750402 | elasped_time: 0.211145 | grad_norm: 0.9032 | lr: 1.5300e-04 | scale: 2048 | step_time: 0.8446 | real_step_time: 0.8663
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 5.695479929447174, 'elasped_time': 0.21114711165428163}
****************************************************************************************************
train | epoch 0/1 | steps 2079 | global_steps 520/6017 | loss: 5.695480 | elasped_time: 0.211147 | grad_norm: 0.8520 | lr: 1.5600e-04 | scale: 2048 | step_time: 0.8446 | real_step_time: 0.8664
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
{'loss': 5.639199876785279, 'elasped_time': 0.2111846923828125}
****************************************************************************************************
train | epoch 0/1 | steps 2119 | global_steps 530/6017 | loss: 5.639200 | elasped_time: 0.211185 | grad_norm: 0.9069 | lr: 1.5900e-04 | scale: 2048 | step_time: 0.8447 | real_step_time: 0.8667
models/output_model/cc-lqs-r0.9-folding-l3/mistral_160M/e1-w2K-bs8-lr0.0006cosine-G4-scr
****************************************************************************************************
